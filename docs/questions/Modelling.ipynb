{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is bias variance trade-off?\n",
    "\n",
    "* The Bias-Variance trade-off is the central problem in supervised machine learning. Ideally, one wants to choose a model that accurately captures the regularities in its training data, but also generilizes well to unseen data. Unfortunately, these goals are contradictory, and often impossible to do both. \n",
    "* __Bias__ represents the error as a result of misaligned assumptions in the learning algorithm that do not represent the true relationship between predictors and the response variable. \n",
    "* __Variance__ represents the error from sensitivity to fluctuations in the training set. High variance can cause an algorithm to model the noise in the training data, rather than intended outputs. \n",
    "* __Discussion__ Models with low-bias are usually more complex (ex: higher-order regression polynomials), enabling them to represent the training set from accurately. However, they may also represent the noise in the trianing set, making their predictions less accurate. On the other hand, models with high-bias are simple (ex: linear regression polynomials), but may produce lower variance prediction when applied beyond the training set. \n",
    "* __Sources:__ [wiki](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Derive bias variance trade-off?\n",
    "\n",
    "\n",
    "* __Derivation of Variance:__  \n",
    "$Var(X) = E[(X-E[X])^2]$  \n",
    "$Var(X) = E[(X^2 + E[X]^2 - 2 * X E[X])]$  \n",
    "$Var(X) = E[X^2] + E[X]^2 - 2 * E[X] * E[X]$  \n",
    "$Var(X) = E[X^2] - E[X]^2$  \n",
    "\n",
    "* __Variance in $y$__  \n",
    "$ Var(y) = E[ (y - E[y])^2]$  \n",
    "$ Var(y) = E[ (E[y] + e - E[y])^2]$  \n",
    "$ Var(y) = E[e^2]$  \n",
    "$ Var(y) = Var(e) + E[e]^2$; But: $E[e] = 0$  \n",
    "$ Var(y) = Var(e)$  \n",
    "\n",
    "* __Sum of Squares Error:__  \n",
    "$SS = E[(y - \\hat{y})^2]$  \n",
    "$SS = E[(y^2 + \\hat{y}^2 - 2 * y * \\hat{y}]$  \n",
    "$SS = E[y^2] + E[\\hat{y}^2] - 2 E(y*\\hat{y})$  \n",
    "$SS = Var(y) + E[y]^2  + Var(\\hat{y}) + E[\\hat{y}]^2  - 2 E(y*\\hat{y})$\n",
    "$SS = Var(e) + Var(\\hat{y}) + \\left( E[y] - E[\\hat{y}]\\right)^2$  \n",
    "$SS = irreducible\\space error + Variance + Bias^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Linear regression algorithm with stochastic gradient decent\n",
    "$J(\\theta) = \\sum_{i=1}^{m} L(\\hat{y_i} - y_i)$  \n",
    "$\\space \\space \\theta = \\theta - \\alpha * \\left(\\hat{y_i} - y_i  \\right) ^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coefficients_sgd(train, learning_rate, iter, pred):\n",
    "    \"\"\"Stochastic Gradient Descent\n",
    "    Args:\n",
    "        train (numpy.ndarray): input data\n",
    "        learning_rate (float): rate of learning\n",
    "        iter (int): No. of iterations\n",
    "    Returns:\n",
    "        list, float:\n",
    "    \"\"\"\n",
    "    coef = [0.0] * len(train[0])\n",
    "    sum_err = 0.0\n",
    "    for i in range(iter):\n",
    "        sum_err = 0.0\n",
    "        for row in train:\n",
    "            yhat = pred(row, coef)\n",
    "            err = yhat - row[-1]\n",
    "            sum_err += err ** 2\n",
    "            coef[0] = coef[0] - learning_rate * err\n",
    "\n",
    "            for j in range(len(row) - 1):\n",
    "                coef[j + 1] = coef[j + 1] - learning_rate * err * row[j]\n",
    "    return coef, sum_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Simple linear regression derivation \n",
    "\n",
    "$y = b_0 + b_1 x$  \n",
    "$RSS = \\sum_{i=1}^{n} \\left( y_i - \\hat{y_i} \\right)$  \n",
    "$\\frac{\\partial{RSS}}{\\partial{b_0}} = \\sum_{i=1}^{n} -2 \\left[ y_i - b_0 - b_1x_i \\right] = 0$  \n",
    "$\\frac{\\partial{RSS}}{\\partial{b_0}} = 2 \\left[ nb_0 + b_1 \\sum_{i=1}^{n}  x_i - \\sum_{i=1}^{n} y_i \\right] = 0$  \n",
    "$b_0 = \\frac{\\sum_{i=1}^{n} y_i}{n} - b_1 \\frac{\\sum_{i=1}^{n} x_i}{n}$  \n",
    "$b_0 = \\bar{y} - b_1 \\bar{x}$ \n",
    "  \n",
    "$\\frac{\\partial{RSS}}{\\partial{b_1}} = \\sum_{i=1}^{n} -2 x_i \\left[ y_i - b_0 - b_1x_i \\right] = 0$  \n",
    "$\\frac{\\partial{RSS}}{\\partial{b_1}} = \\sum_{i=1}^{n} -2 x_i \\left[ y_i - b_0 - b_1x_i \\right] = 0$  \n",
    "$\\frac{\\partial{RSS}}{\\partial{b_1}} = \\sum_{i=1}^{n} -2 x_i \\left[ y_i - \\bar{y} + b_1 \\bar{x} - b_1x_i \\right] = 0$  \n",
    "  \n",
    "$\\frac{\\partial{RSS}}{\\partial{b_1}} = -2 \\sum_{i=1}^{n} \\left[ x_iy_i - \\bar{y} x_i + b_1\\bar{x}x_i - b_1x_i^2 \\right] = 0$  \n",
    "$\\sum_{i=1}^{n} \\left[ x_iy_i - \\bar{y} x_i \\right] - b_1 \\sum_{i=1}^{n} \\left[ b_1x_i^2 - \\bar{x}x_i \\right] = 0$  \n",
    "$b_1 = \\frac{\\sum_{i=1}^{n} \\left( x_iy_i - \\bar{y} x_i \\right)}{\\sum_{i=1}^{n} \\left( x_i^2 - \\bar{x}x_i \\right)}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Gini Impurity\n",
    "\n",
    "$gini\\_impurity = 1 - \\sum_{i}^{C} p_i^2$\n",
    "\n",
    "$gini\\_index:$\n",
    "```\n",
    "for each branch in split:  \n",
    "    Calculate percent branch represents (Used for weighting)\n",
    "    Calculate gini_impurity\n",
    "Weight each branch's gini_impurity by the share of samples it represents\n",
    "Sum the weighted gini index for each split.\n",
    "```\n",
    "\n",
    "$cross\\_entropy  = \\sum_{i}^{C} - p_i \\log(p_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. CART\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decision_tree(train, max_depth, min_leaf_size): \n",
    "    root = get_best_split(train)\n",
    "    split(root, max_depth, min_leaf_size, 1)\n",
    "    return root\n",
    "\n",
    "def split(node, max_depth, min_leaf_size, level):\n",
    "    left, right = node.left, node.right\n",
    "    \n",
    "    if left is None or right is None: to_terminal(node)\n",
    "    \n",
    "    if level > max_depth: return to_terminal(node)\n",
    "    \n",
    "    #Do left and right\n",
    "    if len(left) <= min_leafe_size: node.left = to_terminal(node)\n",
    "    else: \n",
    "        node.left = get_split(left)\n",
    "        split(node.left, max_depth, min_leaf_size, level + 1)\n",
    "\n",
    "def get_split(data):\n",
    "    classes = data['class'].unique()\n",
    "    gini_lowest = 'inf'\n",
    "    split_groups = (None, None)\n",
    "    split_index, split_val = None, None\n",
    "    \n",
    "    for col in data.columns:\n",
    "        for row in data:\n",
    "            a, b = make_split(data, col, row[col])\n",
    "            gini = calc_gini_index([a, b], classes)\n",
    "            if gini < gini_lowest:\n",
    "                gini_lowest = gini\n",
    "                split_groups = (a, b)\n",
    "                split_index = col\n",
    "                split_val = row[col]\n",
    "    return {'groups':split_groups, 'index': split_index, 'val': split_val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Bagged Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(train, test, max_depth, min_size, sample_size, n_trees):\n",
    "    trees = []\n",
    "    for _ in range(n_trees):\n",
    "        sample = subsample(train, sample_size)\n",
    "        tree = build_tree(sample, max_depth, min_size)\n",
    "        trees.append(tree)\n",
    "    predictions = [bagging_predict(trees, row) for row in test.values]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(train, test, max_depth, min_size, sample_ratio, tree_ct,\n",
    "                  feature_ct):\n",
    "    \"\"\"Build a random forest from the training dataset and predict outcomes for\n",
    "    the test dataset\n",
    "\n",
    "    Args:\n",
    "        train (pandas.DataFrame): training dataset\n",
    "        test (pandas.DataFrame): test dataset\n",
    "        max_depth (int): max depth of any tree\n",
    "        min_size (int): min size of the dataset at the terminal node\n",
    "        sample_ratio (float): ratio of re-sampling\n",
    "        tree_ct (int): no. of trees in the foredst\n",
    "        feature_ct (int): no. of features for each tree\n",
    "\n",
    "    Returns:\n",
    "        (list): list of predictions\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "\n",
    "    for _ in range(tree_ct):\n",
    "        sample = subsample(train, sample_ratio)\n",
    "        tree = build_forest(sample, max_depth, min_size, feature_ct)\n",
    "        # print_tree(tree)\n",
    "        trees.append(tree)\n",
    "\n",
    "    predictions = [bagging_predict(trees, row) for row in test.values]\n",
    "    return predictions\n",
    "def build_forest(train, max_depth, min_size, n_features):\n",
    "    \"\"\"Build a tree\n",
    "\n",
    "    Args:\n",
    "        train (pandas.DataFrame): training dataset\n",
    "        max_depth (int): max depth of the tree\n",
    "        min_size (int): min size of samples in terminal node\n",
    "        n_features (int): no. of features for each tree\n",
    "\n",
    "    Returns:\n",
    "        dict: tree with left and right sub-trees\n",
    "    \"\"\"\n",
    "    root = get_split(train.values, n_features)\n",
    "    _build_forest(root, max_depth, min_size, n_features, 1)\n",
    "    return root\n",
    "\n",
    "def get_split(dataset, n_features):\n",
    "    \"\"\"This method randomly picks n_features and returns the best split across\n",
    "    all the features\n",
    "\n",
    "    Args:\n",
    "        dataset(numpy.ndarray): input dataset\n",
    "        n_features (int): no. of features to be considered for splitting\n",
    "\n",
    "    Returns:\n",
    "        dict: of split parameters\n",
    "    \"\"\"\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_idx, b_val, b_score, b_groups = 999, 999, 999, None\n",
    "\n",
    "    indicies = random.sample(range(len(dataset[0]) - 1), n_features)\n",
    "    features = indicies\n",
    "    # print(\"features:\", features)\n",
    "    for feature in features:\n",
    "        for row in dataset:\n",
    "            groups = split_data(dataset, feature, row[feature])\n",
    "            gini = gini_index(groups, class_values)\n",
    "\n",
    "            if gini < b_score:\n",
    "                b_idx, b_val, b_score, b_groups = feature, row[feature], gini, groups\n",
    "\n",
    "    return {\"index\": b_idx, \"value\": b_val, \"groups\": b_groups}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\log\\left( \\frac{p}{1-p}\\right) = \\beta^T X$  \n",
    "\n",
    "Model:   \n",
    "$y_i \\sim Binomial(m_i, p_i) \\space \\forall \\space i = 0, 1, 2, ...m; m = no. of samples$  \n",
    "  \n",
    "$Pr[Y_1 = y_1, Y_2 = y_2... Y_m = y_m | p_1, p_2, p_3...p_m] = \\prod_{i=1}^{m} p_i^{y_i} (1-p_i)^{1-y_i} = \\mathcal{L} $  \n",
    "  \n",
    "$\\log(\\mathcal{L} ) = \\sum_{i=1}^{m} \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right]$  \n",
    "  \n",
    "$\\log(\\mathcal{L} ) = \\sum_{i=1}^{m} \\left[ y_i \\log \\left( \\frac{p_i}{1-p_i}\\right) + \\log(1-p_i) \\right]$  \n",
    "  \n",
    "$\\log(\\mathcal{L} ) = \\sum_{i=1}^{m} \\left[ y_i \\beta^T x_i + \\log\\left(1-\\frac{\\exp{\\beta^T X_i}}{1+ \\exp{\\beta^T X_i}}\\right) \\right]$  \n",
    "  \n",
    "$\\log(\\mathcal{L} ) = \\sum_{i=1}^{m} \\left[ y_i \\beta^T x_i - \\log\\left(1+\\exp{\\beta^T X_i}\\right) \\right]$  \n",
    "  \n",
    "$\\frac{\\partial{\\log(\\mathcal{L})}}{\\partial{\\beta}} = 0 = \\sum_{i=1}^{m} \\left[y_i x_i - \\frac{\\exp(\\beta^Tx_i)}{1+\\exp(\\beta^Tx_i)}  \\right]$  \n",
    "  \n",
    "$\\frac{\\partial{\\log(\\mathcal{L})}}{\\partial{\\beta}} = 0 = \\sum_{i=1}^{m} \\left[x_i \\left(y_i - p(x_i; \\beta) \\right) \\right]$  \n",
    "  \n",
    "$\\frac{\\partial^2{\\log(\\mathcal{L})}}{\\partial{\\beta} \\partial{\\beta}} = - \\sum_{i=1}^{m} x_i\\frac{-\\exp(\\beta^Tx_i)}{(1+ \\exp(\\beta^Tx_i)) (1+ \\exp(\\beta^Tx_i))}$  \n",
    "$\\frac{\\partial^2{\\log(\\mathcal{L})}}{\\partial{\\beta} \\partial{\\beta}} = - \\sum_{i=1}^{m} x_i p_i (1-p_i)$  \n",
    "  \n",
    "$\\beta_{iter + 1} = \\beta_{iter} - \\frac{\\partial{\\log(\\mathcal{L})}}{\\partial^2{\\log(\\mathcal{L})}}$  : Newton method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Derive NN - backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. SVN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__ARIMA(p,d,q) forecasting equation:__ The acronym ARIMA stands for Auto-Regressive Integrated Moving Average. Lags of the stationarized series in the forecasting equation are called __autoregressive__ terms, lags of the forecast errors are called __moving average__ terms, and a time series which needs to be differenced to be made stationary is said to be an __integrated__ version of a stationary series. \n",
    "\n",
    "Random-walk and random-trend models, autoregressive models, and exponential smoothing models are all special cases of ARIMA models.\n",
    "\n",
    "ARIMA models are, in theory, the most general class of models for forecasting a time series which can be made to be 'stationary' by differencing (if necessary), perhaps in conjunction with nonlinear transformations such as logging or deflating (if necessary). \n",
    "\n",
    "* __Stationarity:__ \n",
    "    * A random variable that is a time series is stationary if its statistical properties are all constant over time.  \n",
    "    * A stationary series has no trend, its variations around its mean have a constant amplitude, and it wiggles in a consistent fashion, i.e., its short-term random time patterns always look the same in a statistical sense. \n",
    "    * The latter condition means that its autocorrelations remain constant over time, or equivalently, that its power spectrum remains constant over time.  \n",
    "    * A random variable of this form can be viewed as a combination of signal and noise, and the signal could be a pattern of fast or slow mean reversion, or sinusoidal oscillation, or rapid alternation in sign, and it could also have a seasonal component.  \n",
    "\n",
    "A nonseasonal ARIMA model is classified as an \"ARIMA(p,d,q)\" model, where:\n",
    "* p is the number of autoregressive terms,\n",
    "* d is the number of nonseasonal differences needed for stationarity, and\n",
    "* q is the number of lagged forecast errors in the prediction equation. \n",
    "\n",
    "Forms of ARIMA Models:\n",
    "* __ARIMA(1, 0, 0)__: First order auto regressive $\\hat{y_{t}} = \\mu + \\phi_1 y_{t-1}$\n",
    "* __ARIMA(0, 1, 0)__: Random walk $\\hat{y_{t}} = \\mu + y_{t-1}$\n",
    "* __ARIMA(1, 1, 0)__: Differenced first-order auto regressive $\\hat{y_t} = \\mu + y_{t-1} + \\phi_1 (y_{t-2} - y_{t-1})$  \n",
    "* __ARIMA(0,1,1) without constant__: simple exponential smoothing $\\hat{y_t} = y_{t-1} - \\theta_1 e_{t-1}$ And, $e_x = y_x - \\hat{y_x}$\n",
    "* __ARIMA(1,1,2) without constant__: damped-trend linear exponential smoothing: $\\hat{y_t} = y_{t-1} + \\phi_1 (y_{t-2} - y_{t-1}) + \\theta_1 e_{t-1} + \\theta_2 e_{t-2}$    \n",
    "  \n",
    "\n",
    "__Practical Advise__\n",
    "* Identifying the order of differencing and the constant:\n",
    "    * Rule 1: If the series has positive autocorrelations out to a high number of lags (say, 10 or more), then it probably needs a higher order of differencing.\n",
    "    * Rule 2: If the lag-1 autocorrelation is zero or negative, or the autocorrelations are all small and patternless, then the series does not need a higher order of differencing. If the lag-1 autocorrelation is -0.5 or more negative, the series may be overdifferenced.  BEWARE OF OVERDIFFERENCING.\n",
    "    * Rule 3: The optimal order of differencing is often the order of differencing at which the standard deviation is lowest. (Not always, though. Slightly too much or slightly too little differencing can also be corrected with AR or MA terms. See rules 6 and 7.)\n",
    "    * Rule 4: A model with no orders of differencing assumes that the original series is stationary (among other things, mean-reverting). A model with one order of differencing assumes that the original series has a constant average trend (e.g. a random walk or SES-type model, with or without growth). A model with two orders of total differencing assumes that the original series has a time-varying trend (e.g. a random trend or LES-type model).\n",
    "    * Rule 5: A model with no orders of differencing normally includes a constant term (which allows for a non-zero mean value). A model with two orders of total differencing normally does not include a constant term. In a model with one order of total differencing, a constant term should be included if the series has a non-zero average trend.\n",
    "* Identifying the numbers of AR and MA terms: \n",
    "    * Rule 6: If the partial autocorrelation function (PACF) of the differenced series displays a sharp cutoff and/or the lag-1 autocorrelation is positive--i.e., if the series appears slightly \"underdifferenced\"--then consider adding one or more AR terms to the model. The lag beyond which the PACF cuts off is the indicated number of AR terms.\n",
    "    * Rule 7: If the autocorrelation function (ACF) of the differenced series displays a sharp cutoff and/or the lag-1 autocorrelation is negative--i.e., if the series appears slightly \"overdifferenced\"--then consider adding an MA term to the model. The lag beyond which the ACF cuts off is the indicated number of MA terms.\n",
    "    * Rule 8: It is possible for an AR term and an MA term to cancel each other's effects, so if a mixed AR-MA model seems to fit the data, also try a model with one fewer AR term and one fewer MA term--particularly if the parameter estimates in the original model require more than 10 iterations to converge. BEWARE OF USING MULTIPLE AR TERMS AND MULTIPLE MA TERMS IN THE SAME MODEL.\n",
    "    * Rule 9: If there is a unit root in the AR part of the model--i.e., if the sum of the AR coefficients is almost exactly 1--you should reduce the number of AR terms by one and increase the order of differencing by one.\n",
    "    * Rule 10: If there is a unit root in the MA part of the model--i.e., if the sum of the MA coefficients is almost exactly 1--you should reduce the number of MA terms by one and reduce the order of differencing by one.\n",
    "    * Rule 11: If the long-term forecasts* appear erratic or unstable, there may be a unit root in the AR or MA coefficients.\n",
    "* Identifying the seasonal part of the model: \n",
    "    * Rule 12: If the series has a strong and consistent seasonal pattern, then you must use an order of seasonal differencing (otherwise the model assumes that the seasonal pattern will fade away over time). However, never use more than one order of seasonal differencing or more than 2 orders of total differencing (seasonal+nonseasonal).\n",
    "    * Rule 13: If the autocorrelation of the appropriately differenced series is positive at lag s, where s is the number of periods in a season, then consider adding an SAR term to the model. If the autocorrelation of the differenced series is negative at lag s, consider adding an SMA term to the model. The latter situation is likely to occur if a seasonal difference has been used, which should be done if the data has a stable and logical seasonal pattern. The former is likely to occur if a seasonal difference has not been used, which would only be appropriate if the seasonal pattern is not stable over time. You should try to avoid using more than one or two seasonal parameters (SAR+SMA) in the same model, as this is likely to lead to overfitting of the data and/or problems in estimation.\n",
    "\n",
    "\n",
    "__References:__\n",
    "* [Duke Arima](https://people.duke.edu/~rnau/411arim.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Impact of a given feature on response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Types of error calcualtion\n",
    "\n",
    "* __MSE (Mean Squared Error)__: $\\frac{\\sum_{i=1}^{m} (y_i - \\hat{y_i})^2}{m}$ \n",
    "    * Includes both variance of the estimator (how widely spread the estimates are from one data sample to another) and bias of the estimator (how far off the average estimated value is from the truth) \n",
    "    * RMSE also represents the standard error of the estimator\n",
    "    * Inflates large errors (or outliers)\n",
    "    * Squaring is nicer than taking the absolute value, e.g. it is smooth. It also leads to a definition of variance which has nice mathematical properties, e.g. it is additive. But for me the theorem that really justifies using standard deviation over the mean absolute error is the central limit theorem. The central limit theorem is at work whenever we measure the mean and standard deviation of a distribution we assume to be normal (e.g. heights in a population) and use that to make predictions about the entire distribution, since a normal distribution is completely specified by its mean and standard deviation.\n",
    "* __MAD__: Mean Absolute Deviation $\\frac{\\sum_{i=1}^{m} \\mid y_i - \\hat{y_i} \\mid}{m}$ \n",
    "    * Resistent to outliers\n",
    "* __MAPE__: Mean Absolute Percentage error $\\frac{\\sum_{i=1}^{m} \\mid \\frac{(y_i - \\hat{y_i}) }{y_i} \\mid}{m}$ \n",
    "    * Works well when the response variable is symetric and normally distributed\n",
    "    * Does not work for skewed distribution\n",
    "    * If the response variable has 0 then MAPE has no value\n",
    "    * Direct business interpretation (for ex: % of error in the sales forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. How to evaluate a binary classifier?\n",
    "\n",
    "* __Basic Metrics__  \n",
    " \n",
    "|Metric|Formula|Intepretation|\n",
    "|-------|-----|----------------|\n",
    "|Accuracy|$\\frac{TP +TN}{TP + TN + FP + FN}$|Overall accuracy of the model|\n",
    "|Precision|$\\frac{TP}{TP + FP}$|How many Positives are accurate|\n",
    "|Recall (aka Sensitivity) |$\\frac{TP}{TP + FN}$|Positive sample covered|\n",
    "|Specitivity |$\\frac{TN}{TN + FP}$|Negative sample covered|\n",
    "|F1 Score |$\\frac{2}{\\frac{1}{Precision} + \\frac{1}{Recall}}$|Precision Recall Score|\n",
    "* __ROC (Receiver Operating Characteristics)__: Plot of TPR, FPR\n",
    "* __AUC (Area Under of the Curve)__: Perfect predictor has TPR = 1.0 when FPR = 0.0. Random predictor has the value of TPR = FPR.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. How to deal with imbalanced binary response variable?\n",
    "\n",
    "* __Re-sample data__: For logistic regression models unbalanced training data affects only the estimate of the model intercept (although this of course skews all the predicted probabilities, which in turn compromises your predictions). Fortunately the intercept correction is straightforward: Provided you know, or can guess, the true proportion of 0s and 1s and know the proportions in the training set you can apply a rare events correction to the intercept. Details are in King and Zheng (2001).\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. What models can be used to predict a binary response variable? What are are the differences between these?\n",
    "|Model|Pro|Con|\n",
    "| ------- | ----- | ---------------- |\n",
    "|Logistic Regression|<ul><li>Linear</li><li>Explanability</li><li></li></ul>| <ul> <li>High Bias</li><li>Strict Assumptions about data</li></ul>|\n",
    "|Naive Bayes| <ul><li>Makes no assumption on data</li><li>Explanability</li><li></li></ul>| <ul> <li>High Bias</li><li>Strict Assumptions about data</li></ul>|\n",
    "1. Logistic Regression\n",
    "2. Naive BAyes\n",
    "3. k-NN\n",
    "4. CART\n",
    "5. Bagged Trees\n",
    "6. Random Forest\n",
    "7. XGBoost\n",
    "8. Light GBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17a. How to tune popular classifiers for better results?\n",
    "* SVM: \n",
    "    * linear, polynomial 2, polynominal 3\n",
    "    * Radial with width ${0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2}$\n",
    "    * Regularization Parameter: $10^{-7} - 10^3$\n",
    "* ANN:\n",
    "    * Algo: Gradient Descent backprop\n",
    "    * Hidden Units: 1, 2, 4, 8, 32, 128\n",
    "    * Momentum: {0, 0.2, 0.5, 0.9}\n",
    "    * Intermitent evaluation at various epochs\n",
    "* Logistic Regression:\n",
    "    * No Reg\n",
    "    * Reg Param $10^{-8} - 10^4$\n",
    "* Naive Bayes:\n",
    "    * Single Normal\n",
    "    * Supervised Discretization\n",
    "* KNN: \n",
    "    * Distance: Euclidien, Euclidien + Gain Ratio, \n",
    "    * Distance Weighted and locally weighted averaging varying from $2^0 to 2^{10}$\n",
    "* Random Forests: \n",
    "    * estimators\n",
    "    * max depth\n",
    "    * min leaf size\n",
    "    * size of feature set considered at each split (1, 2, 4, 6, 8, 12, 16, 20)\n",
    "    * balanced\n",
    "* Decision Trees:\n",
    "    * Bayes, ID3, CART, CART0, C4, MML, SMML\n",
    "    * Tree type C44LS, C44BS, MMLLS\n",
    "* Bagged Trees:\n",
    "    * bag size\n",
    "    * Tree type above\n",
    "* Boosted Trees:\n",
    "    * Treetype above\n",
    "    * boosting steps: 2, 4, 8, 16, 32... 2048\n",
    "* Boosted Stumps:\n",
    "    * Single level decision trees\n",
    "    * no. of iterations in powers of 2 untill 2048\n",
    "* Perceptrons: 1, 5, 10, 20, 30\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Why might it be better to include fewer features compared to many?\n",
    "* __Redundancy/Irrelevance:__ If you are dealing with many predictor variables, then the chances are high that there are hidden relationships between some of them, leading to redundancy. Unless you identify and handle this redundancy (by selecting only the non-redundant predictor variables) in the early phase of data analysis, it can be a huge drag on your succeeding steps.\n",
    "\n",
    "    It is also likely that not all predictor variables are having a considerable impact on the dependent variable(s). You should make sure that the set of predictor variables you select to work on does not have any irrelevant ones – even if you know that data model will take care of them by giving them lower significance.\n",
    "\n",
    "* __Overfitting:__ Your model can identify single data points by single features and build a special case just for a single data point. For example, think of a classification problem and a decision tree. If you have feature vectors (x1, x2, ..., xn) with binary features and n points, and each feature vector has exactly one 1, then the tree can simply use this as an identifier.\n",
    "\n",
    "* __Productivity:__ Let’s say you have a project where there are a large number of predictors and all of them are relevant (i.e. have measurable impact on the dependent variable). So, you would obviously want to work with all of them in order to have a data model with very high success rate. While this approach may sound very enticing, practical considerations (such of amount of data available, storage and compute resources, time taken for completion, etc.) make it nearly impossible.\n",
    "\n",
    "* __Understandability:__ Models with fewer predictors are way easier to understand and explain. As the data science steps will be performed by humans and the results will be presented (and hopefully, used) by humans, it is important to consider the comprehensive ability of human brain. This is basically a trade-off – you are letting go of some potential benefits to your data model’s success rate, while simultaneously making your data model easier to understand and optimize.\n",
    "    \n",
    "[KDNugget Why it may be better to have fewer predictors in Machine Learning models?](https://www.kdnuggets.com/2017/04/must-know-fewer-predictors-machine-learning-models.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. What problems arise if the distribution of the new (unseen) test data is significantly different than the distribution of the training data?\n",
    "\n",
    "1. __Sample selection bias:__ Non-random split between test and train data\n",
    "2. __Population drift (co-variate shift):__ Test and train populations are different (for ex: test subjects that recieve different treatment)\n",
    "3. __Non-stationary environments:__ Change in test subject behaviour (for ex: new types of spam, fraud)  \n",
    "\n",
    "[KDNuggets Test data is from different distribution](https://www.kdnuggets.com/2017/02/17-data-science-interview-questions-answers.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to calculate the no. of distint values of a large number set? How does hyper log-log work?\n",
    "* Intuition: \n",
    "    * A set of random numbers is represented in binary can be represented as a tree with each node representing the next leading bit\n",
    "    * This allows one to measure the hieght of the tree by counting the no. of leading 0s (or 1s)\n",
    "    * Given that the leaves of the binary tree are the unique values, the no. of leaves in the tree is the count of distinct elements  \n",
    "    * Thus the no. of unique elements is $2^h$, where $h$ is the no. of leading zeroes\n",
    "    * If one has n distinct items, they can be stored in a balanced binary tree of height log(n). To store the height itself, one needs log(height)=log(log(n)) bits.\n",
    "* Optimizations:\n",
    "    * Usually a set of random numbers are not uniformly distributed, but a good hashing function can deliver more uniform distribution  \n",
    "[Stefan Savev: Hyper-log-log in pictures](http://stefansavev.com/blog/an-intuitive-explanation-of-hyperloglog-algorithm-for-approximate-distinct-count/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link Prediction:How would you design the people you may know feature on Linkedin or FB?\n",
    "* General Link Prediction Problem Domain: Org Networks, Terrorist Networks, Social Networks\n",
    "* Measure of 'proximity' is key (for ex: no. of common friends, institutions, etc.,)\n",
    "* Intuition:\n",
    "    1. __Similarity Measure:__ Similar demographics, interests, etc\n",
    "    2. __Strength of Ties:__ If A is linked to B, B is linked to C, then A is likely to be linked to C\n",
    "    3. __Generalized Strength of Ties (Common Neighbour):__ Lots of common neighbours or close ties, the more likely that a nodes will be linked\n",
    "    4. __Graph Distance:__ Shortest Path, Katz Distance\n",
    "    5. __Random Walks from Nodes:__ Nodes that interact often and/or takes little time to interact are likely to be linked\n",
    "    6. __High-Degree Nodes:__ Nodes with lot of connections tend to be more connected\n",
    "    7. __Communities:__ Detecting communities is essentially a clusterting or bgbdimension reduction problem\n",
    "* Metrics:\n",
    "    1. Measure of common neighbours:\n",
    "        1. $neighbours(a) \\cap neighbours(b) $\n",
    "        2. Jaccard Similarity: $\\frac{neighbours(a) \\cap neighbours(b) }{neighbours(a) \\cup neighbours(b) }$\n",
    "        3. Adar (Comparison all y linkage to x): $\\sum\\left[ log(neighbours(a) \\cap neighbours(b)) \\right]^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How would you construct a feed to show relevant content for a site that involved user interactions with items?\n",
    "* PageRank: \n",
    "    * Basic Formula: $PR(j) = \\frac{1-d}{N} + d * \\sum_{i: i->j} \\frac{PR(i)}{D_i}$\n",
    "    * Implementation Notes: PR is usually recalculated when the page is re-crawled. Additional optimization can be made to add additional weight to freshness, qualitative measure of quality, realiability. \n",
    "* __EdgeRank:__\n",
    "    * Features: Affinity, Wieght, Time Decay\n",
    "        * Affinity: Between subject the edge creator. Factors (a) strength of action (b) how close the edge creator is to the user (c) age of edge\n",
    "        * Edge Weight: For ex:  Comment > Like\n",
    "        * Time Decay: linear, hyperbolic (1/x) or exponential (factor = 1/x)\n",
    "* __Search Engine Ranking: __\n",
    "    * Features: \n",
    "        1. Domain Level link features\n",
    "        2. Page-Level link features\n",
    "        3. Page-level keyword and content based features\n",
    "        4. Page-level keyword-agnostic features\n",
    "        5. Engagement and Traffic query data\n",
    "        6. Domain-Level Brand Metrics\n",
    "        7. Domain-level Keyword Usage\n",
    "        8. Domain-level Keyword-Agnostic Features\n",
    "        9. Page-Level social metrics\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is calibration and why is it required in \n",
    "The output of some learning algorithms such as ANN, logistic regression, bagged trees and random forests can be interpreted as the conditional probability of the class given the input. The common implemen tation of other metho ds such as SVM and boosting, however, are not designed to predict probabilities. \n",
    "Note that calibrating can affect metrics other than probability metrics such as squared loss. It can affect accuracy by changing the optimal threshold (for calibrated predictions the optimum threshold will be near 0.5). Calibration can hurt predictions from methods such as ANN and logistic regression. \n",
    "\n",
    "To  overcome this, we  use two different  methods to map the predictions from each learning algorithm to calibrated probabilities. \n",
    "* __Isotonic Regression:__ a method which fits a non-parametric non-decreasing function to the predictions. Isotonic Regression can affect AUC by creating ties on calibration plateaus where prior to calibration there was a definite ordering.\n",
    "* __Platt's method:__ a method which  fits a sigmoid to the predictions\n",
    "\n",
    "A fact that is not apparent from the paper below is that calibration with isotonic regression works better than calibrating with Platt's method, or no calibration, on most problems and thus was used for almost all of the results reported. Since our validation sets always are larger than 1000 examples, this confirms the  findings in (Niculescu-Mizil & Caruana, 2005) that isotonic regression is preferred with large validation sets.\n",
    "\n",
    "[An Emperical Evaluation of Supervised Learning In High Dimensions](http://icml2008.cs.helsinki.fi/papers/632.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Program a Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Program a k-NN algorithm (a) iterative and (b) vectorized"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "35. What are differences between generative and discriminative models? Examples.\n",
    "36. Derive likelihood function for BG NBD\n",
    "37. Typical loss functions used: \n",
    "    a. Least Squared Error\n",
    "    b. Logistic Loss\n",
    "    c. Hinge Loss\n",
    "    d. Cross-entropy\n",
    "38. What is the cost function in gradient descent?\n",
    "39. What is the general form of gradient descent? What are the typical parameters to control gradient descent?\n",
    "40. What is Newton's algorithm? What is the Newton-Rahpson method?\n",
    "41. Derive linear regression co-efficients using Normal equation?\n",
    "42. What is the mathematical form of Least Mean Square Algorithm?\n",
    "43. What is locally weighted regression? \n",
    "44. What is the sigmoid function\n",
    "45. What is the general form of logistic regression\n",
    "46. What is the genral form of softmax regression?\n",
    "47. What are generalized regression models? How can the Bernauli, Gaussian, Poisson, Geomertric distributions be used within GLM?\n",
    "48. What are the assumptions in GLM?\n",
    "49. What is SVM? How does it work?\n",
    "50. How does Gaussian Discriminant analysis work?\n",
    "51. Learning Theory: What is Union Bound?\n",
    "52. Learning Theory: What is Hoeffding inequality?\n",
    "53. Learning Theory: What is Training Error?\n",
    "54. Learning Theory: What is Probably Approximately Correct (PAC)?\n",
    "55. Learning Theory: What is Shattering?\n",
    "56. Learning Theory: What is Upper Bound Theorem?\n",
    "57. Learning Theory: What is VC dimension?\n",
    "58. Learning Theory: What is Vapnik Theorem?\n",
    "59. What is EM algorithm? How is it used in discovering LAten variables?\n",
    "60. What is k-means clustering? How does the algorithm work?\n",
    "61. How to optimize k-means? how to find optimal k?\n",
    "62. What are the assumptions with k-means algorithm?\n",
    "63. What is k-protype algorithm? When is it typically used?\n",
    "64. What is Hierarchical clustering? What are the different linkage functions that can be used?\n",
    "65. What are the metrics that can be used to assess clusters? Solihouette, Calinski-Harabaz?\n",
    "66. What is PCA? How does it work? Code it up\n",
    "67. What is ICA? How does it work?\n",
    "68. What is NN? What is the general form?\n",
    "69. What are the typical activation functions used? Describe Sigmoid, Tanh, ReLU, Leaku ReLU?\n",
    "70. How does the backpropagation algorithm work?\n",
    "    a. Cross-entropy loss\n",
    "    b. Learning Rate\n",
    "    c. Backpropagation\n",
    "    d. Updating weights\n",
    "    e. Dropout\n",
    "71. What is CNN?\n",
    "    a. Convolutional Layer Requirement\n",
    "    b. Batch normalization\n",
    "72. What is RNN?\n",
    "    a. Types of gates? Input, Forget, Gate, Output gate\n",
    "    b. LSTM\n",
    "73. Re-inforcement Learning and Control\n",
    "    a. What is policy\n",
    "    b. What is markov decision process\n",
    "    c. What is value function?\n",
    "    d. What are bellman equation\n",
    "    e. Value iteration algorithm\n",
    "    f. MLE\n",
    "    g. Q-learning\n",
    "74. Classification evaluation metrics:\n",
    "    a. Accuracy, Precision, Recal (Sensitivity), Specificity, F1 Score\n",
    "    b. ROC (TPR aka Recall aka Sensitivity, FPR aka 1- specificity)\n",
    "    c. AUC\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given training data on tweets and their tweets, how would you predict the no. of re-tweets of a given tweet after 7 days after only observing 2 days worth of data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How would you predict who someone may want to send a Snapchat or Gmat to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How would you suggest to a franchise where to open a new store?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In a search engine, query auto complete solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given a database of all previous alumni donations to your university, how would you predict which recent alumni are more likely to donate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You're Uber and you want to design a heatmap to recommend to drivers where to wait for passenger. How would you approach this?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How would you build a model to predict a March Madness bracket?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You want to run a regression to predict the probability of a flight delay, but there are flights with delays up to 12 hours that are really messing up your model. How will you address this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 75. Regression Metrics:\n",
    "* **Total Sum of Squares (TSS):** Measures the variation in the observed data  \n",
    "$ \\sum_{i=0}^{m} (y_i - \\bar{y})^2$   \n",
    "\n",
    "* __Residual Sum of Squares (RSS):__ Measures the variation in the modelling errors  \n",
    "$ \\sum_{i=0}^{m} (y_i - \\hat{y_i})^2$  \n",
    "* __Explained Sum of Squares (ESS):__  Measures variation in the modelled values  \n",
    "$ \\sum_{i=0}^{m} (\\hat{y_i} - \\bar{y})^2$   \n",
    "\n",
    "* $R^2$ or co-efficient of variation   \n",
    "$ (1- \\frac{RSS}{TSS})$  \n",
    "  \n",
    "* Model performance: Mallow's Cp, AIC, BIC, Adjusted R^2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 76. Regularization:\n",
    "* __Definition:__ Regularization is a technique used to reduce the complexity of the model, the objective is to increase bias and avoid overfitting the training sample. Regularization is usually done through addition of regularization term to the cost function of the machine learning model. \n",
    "* __LASSO aka L1 Regularization:__ Lasso shriks co-efficients towards 0. When the $\\lambda$ is sufficiently large, the lasso method is likely to end up  shrinking some of the coefficients to 0. If there is a group of highly correlated variables, Lasso tends to select one from the group and ignore the rest. $$J(\\theta) = \\sum_{i = 1}^{m}{\\left( y_i - \\theta_0 - \\sum_{j=1}^{n} \\theta_j x_{i\\space j}\\right) ^2} + \\lambda \\sum_{j=1}^{n}{\\mid \\theta_j \\mid}$$\n",
    "* __Ridge aka L2 Regulization:__ Ridge regularization shriks co-efficient to 0. But, due to the nature of the penalty term, ridge penalization always yields models that have all the $n$ predictors. $$J(\\theta) = \\sum_{i = 1}^{m}{\\left( y_i - \\theta_0 - \\sum_{j=1}^{n} \\theta_j x_{i\\space j}\\right) ^2} + \\lambda \\sum_{j=1}^{n}{ \\theta_j}^2$$\n",
    "* __Elastic Net:__ L1 regularization is conservative with highly-correlated variables. Elastic net combines the cost function of both L1 and L2 to allow for more flexbility when compared to L1. \n",
    "$$J(\\theta) = \\sum_{i = 1}^{m}{\\left( y_i - \\theta_0 - \\sum_{j=1}^{n} \\theta_j x_{i\\space j}\\right) ^2} + \\lambda_1 \\sum_{j=1}^{n}{\\mid \\theta_j \\mid} + \\lambda_2 \\sum_{j=1}^{n}{ \\theta_j}^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 77. Diagnostics:\n",
    "* Discovering overfitting, underfitting through training and cv error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
